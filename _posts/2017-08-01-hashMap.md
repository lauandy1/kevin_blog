---
layout: post
title: HashMap
author: andy
tags:  collection
categories:  java
excerpt: HashMap底层结构、扩容等
---

* TOC
{:toc}
# 总体介绍
HashMap实现了Map接口，允许放入null元素，除该类未实现同步外，其余跟Hashtable大致相同，跟TreeMap不同，该容器不保证元素顺序，根据需要该容器可能会对元素重新哈希，元素的顺序也会被重新打散，因此不同时间迭代同一个HashMap的顺序可能会不同。

根据对冲突的处理方式不同，哈希表有两种实现方式，一种开放地址方式（Open addressing），另一种是冲突链表方式（Separate chaining with linked lists）。Java HashMap采用的是冲突链表方式。

![hashMap.jpeg](/images/collection/hashMap.jpeg)

从上图容易看出，如果选择合适的哈希函数，put()和get()方法可以在常数时间内完成。但在对HashMap进行迭代时，需要遍历整个table以及后面跟的冲突链表。因此对于迭代比较频繁的场景，不宜将HashMap的初始大小设的过大。

有两个参数可以影响HashMap的性能：初始容量（inital capacity）和负载系数（load factor）。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。

将对向放入到HashMap或HashSet中时，有两个方法需要特别关心：hashCode()和equals()。hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到HashMap或HashSet中，需要@Override hashCode()和equals()方法。

# 方法剖析

get()

get(Object key)方法根据指定的key值返回对应的value，该方法调用了getEntry(Object key)得到相应的entry，然后返回entry.getValue()。因此getEntry()是算法的核心。

算法思想是首先通过hash()函数得到对应bucket的下标，然后依次遍历冲突链表，通过key.equals(k)方法来判断是否是要找的那个entry。

![hashmap-get.jpeg](/images/collection/hashmap-get.jpeg)

上图中hash(k)&(table.length-1)等价于hash(k)%table.length，原因是HashMap要求table.length必须是2的指数，因此table.length-1就是二进制低位全是1，跟hash(k)相与会将哈希值的高位全抹掉，剩下的就是余数了。


    //getEntry()方法

    final Entry<K,V> getEntry(Object key) {

        ......

        int hash = (key == null) ? 0 : hash(key);

        for (Entry<K,V> e = table[hash&(table.length-1)];//得到冲突链表

             e != null; e = e.next) {//依次遍历冲突链表中的每个entry

            Object k;

            //依据equals()方法判断是否相等

            if (e.hash == hash &&

                ((k = e.key) == key || (key != null && key.equals(k))))

                return e;

        }

        return null;

    }

put()

put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于getEntry()方法；如果没有找到，则会通过addEntry(int hash, K key, V value, int bucketIndex)方法插入新的entry，插入方式为头插法。

![hashmap-put.jpeg](/images/collection/hashmap-put.jpeg)

    //addEntry()

    void addEntry(int hash, K key, V value, int bucketIndex) {

        if ((size >= threshold) && (null != table[bucketIndex])) {

            resize(2 * table.length);//自动扩容，并重新哈希

            hash = (null != key) ? hash(key) : 0;

            bucketIndex = hash & (table.length-1);//hash%table.length

        }

        //在冲突链表头部插入新的entry

        Entry<K,V> e = table[bucketIndex];

        table[bucketIndex] = new Entry<>(hash, key, value, e);

        size++;

    }


remove()


remove(Object key)的作用是删除key值对应的entry，该方法的具体逻辑是在removeEntryForKey(Object key)里实现的。removeEntryForKey()方法会首先找到key值对应的entry，然后删除该entry（修改链表的相应指针）。查找过程跟getEntry()过程类似。

![hashmap-remove.jpeg](/images/collection/hashmap-remove.jpeg)

    //removeEntryForKey()

    final Entry<K,V> removeEntryForKey(Object key) {

        ......

        int hash = (key == null) ? 0 : hash(key);

        int i = indexFor(hash, table.length);//hash&(table.length-1)

        Entry<K,V> prev = table[i];//得到冲突链表

        Entry<K,V> e = prev;

        while (e != null) {//遍历冲突链表

            Entry<K,V> next = e.next;

            Object k;

            if (e.hash == hash &&

                ((k = e.key) == key || (key != null && key.equals(k)))) {//找到要删除的entry

                modCount++; size--;

                if (prev == e) table[i] = next;//删除的是冲突链表的第一个entry

                else prev.next = next;

                return e;

            }

            prev = e; e = next;

        }

        return e;

    }

    

# HashMap的复杂度
如图是ArrayList/LinkedList/HashMap三个数据结构的复杂度对比，可以看出HashMap整体上性能都非常不错，但是不稳定，为O(N/Buckets)，N就是以数组中没有发生碰撞的元素。

获取	查找	添加/删除	空间	

ArrayList	O(1)	O(1)	O(N)	O(N)

LinkedList	O(N)	O(N)	O(1)	O(N)

HashMap	O(N/Bucket_size)	O(N/Bucket_size)	O(N/Bucket_size)	O(N)

注：发生碰撞实际上是非常稀少的，所以N/Bucket_size约等于1

HashMap是对Array与Link的折衷处理，Array与Link可以说是两个速度方向的极端，Array注重于数据的获取，而处理修改（添加/删除）的效率非常低；Link由于是每个对象都保持着下一个对象的指针，查找某个数据需要遍历之前所有的数据，所以效率比较低，而在修改操作中比较快。

# HashMap的实现

## 什么是hash，什么是碰撞？

    Hash：是一种信息摘要算法，它还叫做哈希，或者散列。我们平时使用的MD5,SHA1,SSL中的公私钥验证都属于Hash算法，
    通过输入key进行Hash计算，就可以获取key的HashCode()，比如我们通过校验MD5来验证文件的完整性。
    碰撞：好的Hash算法可以出计算几乎出独一无二的HashCode，如果出现了重复的hashCode，就称作碰撞;

就算是MD5这样优秀的算法也会发生碰撞，即两个不同的key也有可能生成相同的MD5。

## 对key进行Hash计算

在JDK8中，由于使用了红黑树来处理大的链表开销，所以hash这边可以更加省力了，只用计算hashCode并移动到低位就可以了。

    static final int hash(Object key) {
        int h;
        //计算hashCode，并无符号移动到低位
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }

下面给出几个常用的哈希码的算法。

Object类的hashCode.返回对象的内存地址经过处理后的结构，由于每个对象的内存地址都不一样，所以哈希码也不一样。这个是native方法，这个取决于JVM的设计，一般是某种地址的偏移。

String类的hashCode.根据String类包含的字符串的内容，根据一种特殊算法返回哈希码，只要字符串的内容相同，返回的哈希码也相同。

Integer等包装类，返回的哈希码就是Integer对象里所包含的那个整数的数值，例如Integer i1=new Integer(100),i1.hashCode的值就是100 。由此可见，2个一样大小的Integer对象，返回的哈希码也一样。

int，char这样的基础类，它们不需要hashCode，如果需要存储时，将进行自动装箱操作，计算方法同上。

## 获取到当前的位置

计算了Hash，我们现在要把它插入数组中了

    i = (tab.length - 1) & hash；

通过位运算，确定了当前的位置，因为HashMap数组的大小总是2^n，所以实际的运算就是 (0xfff…ff) & hash ，这里的tab.length-1相当于一个mask，滤掉了大于当前长度位的hash，使每个i都能插入到数组中。

## 生成包装类
这个对象是一个包装类，Node<K,V>，内部有key,value,hash还有next，可以看出来它是一个链表。

    static class Node<K,V> implements Map.Entry<K,V> {
            final int hash;
            final K key;
            V value;
            Node<K,V> next;
            //getter and setter .etc.
    }

## 插入包装类到数组
如果输入当前的位置是空的，就插进去，如图，左为插入前，右为插入后

    0           0

    |           |

    1 -> null   1 - > null

    |           |

    2 -> null   2 - > null

    |           | 

    ..-> null   ..- > null

    |           | 

    i -> null   i - > new node

    |           |

    n -> null   n - > null

如果当前位置已经有了node，且它们发生了碰撞，则新的放到前面，旧的放到后面，这叫做链地址法处理冲突。

    0           0

    |           |

    1 -> null   1 - > null

    |           |

    2 -> null   2 - > null

    |           | 

    ..-> null   ..- > null

    |           | 

    i -> old    i - > new - > old

    |           |

    n -> null   n - > null

我们可以发现，失败的hashCode算法会导致HashMap的性能下降为链表，所以想要避免发生碰撞，就要提高hashCode结果的均匀性。
当然，在JDK8中，采用了红黑二叉树进行了处理，这个我们后面详细介绍。   

# 什么是Hash攻击
通过请求大量key不同，但是hashCode相同的数据，让HashMap不断发生碰撞，硬生生的变成了SingleLinkedList

    |

    1 -> a ->b -> c -> d(撞！撞！撞！复杂度由O(1)变成了O(N))

    |

    2 -> null(本应该均匀分布，这里却是空的)

    |

    3 -> null

    |

    4 -> null

这样put/get性能就从O(1)变成了O(N)，CPU负载呈直线上升，形成了放大版DDOS的效果，这种方式就叫做hash攻击。在Java8中通过使用TreeMap，提升了处理性能，可以一定程度的防御Hash攻击。

# 扩容
如果当表中的75%已经被占用，即视为需要扩容了

	(threshold = capacity * load factor ) < size

它主要有两个步骤：


## 容量加倍


左移1位，就是扩大了两倍，用位运算取代了乘法运算


    newCap = oldCap << 1;

    newThr = oldThr << 1;


## 遍历计算Hash

    for (int j = 0; j < oldCap; ++j) {

                    Node<K,V> e;

                    //如果发现当前有Bucket

                    if ((e = oldTab[j]) != null) {

                        oldTab[j] = null;

                        //如果这里没有碰撞

                        if (e.next == null)

                            //重新计算Hash，分配位置

                            newTab[e.hash & (newCap - 1)] = e;

                        //这个见下面的新特性介绍，如果是树，就填入树

                        else if (e instanceof TreeNode)

                            ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);

                        //如果是链表，就保留顺序....目前就看懂这点

                        else { // preserve order

                            Node<K,V> loHead = null, loTail = null;

                            Node<K,V> hiHead = null, hiTail = null;

                            Node<K,V> next;

                            do {

                                next = e.next;

                                if ((e.hash & oldCap) == 0) {

                                    if (loTail == null)

                                        loHead = e;

                                    else

                                        loTail.next = e;

                                    loTail = e;

                                }

                                else {

                                    if (hiTail == null)

                                        hiHead = e;

                                    else

                                        hiTail.next = e;

                                    hiTail = e;

                                }

                            } while ((e = next) != null);

                            if (loTail != null) {

                                loTail.next = null;

                                newTab[j] = loHead;

                            }

                            if (hiTail != null) {

                                hiTail.next = null;

                                newTab[j + oldCap] = hiHead;

                            }

                        }

                    }

                }

由此可以看出扩容需要遍历并重新赋值，成本非常高，所以选择一个好的初始容量非常重要。

# 如何提升性能？
解决扩容损失：如果知道大致需要的容量，把初始容量设置好以解决扩容损失；

比如我现在有1000个数据，需要 1000/0.75 = 1333 ,又 1024 < 1333 < 2048，所以最好使用2048作为初始容量。

解决碰撞损失：使用高效的HashCode与loadFactor，这个…由于JDK8的高性能出现，这儿问题也不大了。

解决数据结构选择的错误：在大型的数据与搜索中考虑使用别的结构比如TreeMap，这个就是积累了，一般需要key排序时，建议使用TreeMap

# HashMap与HashTable的主要区别
在很多的Java基础书上都已经说过了，他们的主要区别其实就是Table加了线程同步保护

HashTable线程更加安全，代价就是因为它粗暴的添加了同步锁，所以会有性能损失。

其实有更好的concurrentHashMap可以替代HashTable

# JDK8中HashMap的新特性
如果某个桶中的链表记录过大的话（当前是TREEIFY_THRESHOLD = 8），就会把这个链动态变成红黑二叉树，使查询最差复杂度由O(N)变成了O(logN)。

    //e 为临时变量，p为当前的链

    for (int binCount = 0; ; ++binCount) {

        if ((e = p.next) == null) {

            p.next = newNode(hash, key, value, null);

            if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st

                treeifyBin(tab, hash);

            break;

        }

        if (e.hash == hash &&

            ((k = e.key) == key || (key != null && key.equals(k))))

            break;

        p = e;

    }


# 参考
HashMap的实现与优化 ImportNew

